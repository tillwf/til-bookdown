## How to deploy an HuggingFace model API on Google Cloud Function

Create a file `main.py` like that:

```python
from transformers import TFBertForSequenceClassification
from transformers import AutoTokenizer
import tensorflow as tf

model = None
tokenizer = None

def predict(request):
  global model
  global tokenizer
  if model is None:
    model = TFBertForSequenceClassification.from_pretrained("jonaskoenig/xtremedistil-l6-h256-uncased-question-vs-statement-classifier", cache_dir="/tmp")
    tokenizer = AutoTokenizer.from_pretrained("jonaskoenig/xtremedistil-l6-h256-uncased-question-vs-statement-classifier", cache_dir="/tmp")

  params = request.get_json()
  sentence = params["description"]
  predictions = model(**tokenizer(sentence, return_tensors="tf"))
  probabilities = tf.nn.softmax(predictions.logits[0], axis=0).numpy()
  return {
    "no_question": float(probabilities[0]),
    "question": float(probabilities[1])
  }
```

a file `requirements.txt` like that:

```python
tensorflow==2.12.0
transformers==4.27.4
```

a `Dockerfile` like that:

```
FROM python:3.10.6

ENV PYTHONUNBUFFERED 1

EXPOSE 8000
WORKDIR /app

COPY requirements.txt ./
RUN pip install --upgrade pip && \
    pip install -r requirements.txt

COPY . ./

ENV PYTHONPATH huggingfastapi

CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]
```

You can now build your image and push it to your registry:

```bash
docker build  -t <image_url> -f Dockerfile .
docker push <image_url>
```

and deploy it on Google Cloud Run:

```bash
gcloud run deploy <image_name> --image <image_url>:latest
                           --region europe-west1
                           --port 8000
                           --memory 4Gi
```
